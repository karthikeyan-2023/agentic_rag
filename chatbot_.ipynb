{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh3dnWZRhIDR",
        "outputId": "bc2c1c09-ae95-448c-d1b1-6fa905fc301b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 1:required libraies to download\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "UdNzwHLWf35A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 2:\n",
        "# Load PDF and extract clean text\n",
        "loader = PyPDFLoader(\"/content/sample (3).pdf\")\n",
        "documents = loader.load()\n"
      ],
      "metadata": {
        "id": "Eo4U8ichf49d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Semantic chunking\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "fGNNFmkMf_8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Batch embedding creation & caching(temporal memory)\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "cache = {}\n",
        "\n",
        "def get_embedding(text):\n",
        "    if text in cache:\n",
        "        return cache[text]\n",
        "    emb = embedding_model.embed_query(text)\n",
        "    cache[text] = emb\n",
        "    return emb\n",
        "#batch embedding of all chunks\n",
        "embeddings = [get_embedding(chunk.page_content) for chunk in chunks]\n"
      ],
      "metadata": {
        "id": "8wyu2OSAgAmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Store embeddings in FAISS vector store\n",
        "vector_store = FAISS.from_texts([chunk.page_content for chunk in chunks], embedding_model)"
      ],
      "metadata": {
        "id": "zsG0FersgUQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6 : Set up retriever and retrieval with reranking\n",
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})"
      ],
      "metadata": {
        "id": "FgHLhAeFgcJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Step 7: prompt templete\n",
        "prompt_template = \"\"\"\n",
        "Use the following context to answer the question. If you don't know the answer, say so.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)"
      ],
      "metadata": {
        "id": "yRgu_WQEgjGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 8 : load model\n",
        "\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Create a text generation pipeline\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100)\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WBRU82GkraY",
        "outputId": "386c433f-3dfb-47bc-abbb-0e3c9f5573d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 9:  conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", output_key='result')"
      ],
      "metadata": {
        "id": "NfLZbTMNgpEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 10: Build RetrievalQA\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                      retriever=retriever,\n",
        "                                      return_source_documents=True,\n",
        "                                      chain_type_kwargs={\"prompt\": prompt},\n",
        "                                      memory=memory)\n"
      ],
      "metadata": {
        "id": "MyGYGjsqgwLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  query\n",
        "query = \"Phases of NLP\"\n",
        "result = qa_chain.invoke({\"query\": query})\n",
        "print(\"Answer:\", result['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok2OQXdBg0qP",
        "outputId": "f8d0c4df-b1ee-4dcb-f4ec-1ad2dc12223f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: \n",
            "Use the following context to answer the question. If you don't know the answer, say so.\n",
            "\n",
            "Context:\n",
            "process language and each phase helps in understanding structure and meaning of \n",
            "human language. In this article, we will understand these phases. \n",
            " \n",
            "Phases of NLP \n",
            "1. Lexical and Morphological Analysis \n",
            "Lexical Analysis \n",
            "It focuses on identifying and processing words (or lexemes) in a text. It breaks down \n",
            "the input text into individual tokens that are meaningful units of language such as words \n",
            "or phrases. \n",
            "Key tasks in Lexical analysis: \n",
            "1. Tokenization: Process of dividing a text into smaller chunks called tokens. For example \n",
            "the sentence \"I love programming\" would be tokenized into [\"I\", \"love\", \n",
            "\"programming\"]. \n",
            "2. Part-of-Speech Tagging: Assigning parts of speech such as noun, verb, adj ective to \n",
            "each token in the sentence. This helps us to understand grammatical roles of words in \n",
            "the context. \n",
            "Example: Consider the sentence: \"I am reading a book.\"\n",
            "\n",
            "diversity of human language. Let's discuss 10 major challenges in NLP: \n",
            "1. Language differences \n",
            "The human language and understanding is rich and intricated and there many languages \n",
            "spoken by humans. Human language is diverse and thousand  of human languages \n",
            "spoken around the world with having its own grammar, vocabular and cultural nuances. \n",
            "Human cannot understand all the languages and the productivity of human language is \n",
            "high. There is ambiguity in natural language since same words and p hrases can have \n",
            "different meanings and different context. This is the major challenges in understating \n",
            "of natural language. \n",
            "There is a  complex syntactic structures and grammatical rules of natural languages. \n",
            "The rules are such as word order, verb, conjugation, tense, aspect and agreement. There \n",
            "is rich semantic content in human language that allows speaker to convey a wide range \n",
            "of meaning through words and sentences. Natural Language is pragmatics which means\n",
            "\n",
            "Question:\n",
            "Phases of NLP\n",
            "1. Syntax Analysis \n",
            "The syntactic analysis is part of the process of developing a sentence and then forming the sentence \n",
            "\n",
            "into a sentence. \n",
            "\n",
            "Key tasks in Syntax analysis: \n",
            "\n",
            "1. Language Differences \n",
            "The human language is all about syntax. \n",
            "\n",
            "The human language has a special syntax that is very strong. \n",
            "\n",
            "There are many syntactic structures and grammatical rules \n",
            "that can be used in language analysis. \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XoSYkFFsoc6d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}